{"cells":[{"cell_type":"markdown","metadata":{"id":"9E5Jowj2q2JI"},"source":["<div style=\"border:2px solid #4F8EF7;padding:14px;border-radius:10px;background:#F5FAFF\">\n","<h2>Class Transcriber — Overview</h2>\n","<p>\n","Transcribes class audio/video, pulls Forum metadata (title, section/schedule, date/time, attendance, events), and generates a polished PDF + CSV.\n","Supports <b>Local</b>, <b>Google Drive</b>, and <b>Direct URL</b> inputs; outputs can be saved to <b>Local</b> or <b>Google Drive</b>.\n","</p>\n","<h3>Start Here</h3>\n","<ol>\n","  <li>Runtime → <b>Change runtime type</b> → T4 GPU (or CPU if GPU unavailable).</li>\n","  <li>Runtime → <b>Run all</b>. The notebook pauses to ask for: Forum cURL, audio source, output destination, and privacy.</li>\n","</ol>\n","<p><b>Use your Minerva account:</b> please sign in with <code>@uni.minerva.edu</code> or <code>@minerva.edu</code>.</p>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKiMeNBdq2JJ"},"outputs":[],"source":["# =========================\n","#  STEP 1 — GOOGLE AUTH (MINERVA-ONLY)\n","# =========================\n","# Sign in with @uni.minerva.edu or @minerva.edu. Access is denied otherwise.\n","try:\n","    from google.colab import auth  # type: ignore\n","except Exception as e:\n","    raise RuntimeError(\"Open this notebook in Google Colab to authenticate.\") from e\n","\n","auth.authenticate_user()\n","\n","import google.auth\n","from google.auth.transport.requests import Request\n","import requests\n","\n","creds, _ = google.auth.default()\n","creds.refresh(Request())\n","token = creds.token\n","\n","resp = requests.get(\n","    \"https://www.googleapis.com/oauth2/v1/userinfo?alt=json\",\n","    headers={\"Authorization\": f\"Bearer {token}\"}\n",")\n","resp.raise_for_status()\n","email = resp.json().get(\"email\")\n","print(\"Authenticated as:\", email)\n","\n","allowed_domains = ( \"@uni.minerva.edu\", \"@minerva.edu\" )\n","if not email or not email.endswith(allowed_domains):\n","    raise PermissionError(\n","        \"Access restricted: sign in with your Minerva account \"\n","        \"(@uni.minerva.edu or @minerva.edu) and re-run.\"\n","    )"]},{"cell_type":"markdown","source":["## Class Transcriber\n","Transcribes class recordings, fetches Forum metadata, and generates PDF/CSV\n","with attendance and class events. Supports local, Google Drive, and direct URL\n","inputs; outputs can be saved locally or to Google Drive. Includes privacy modes\n","(names / ids / both)."],"metadata":{"id":"rYu0hqH45dTi"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"eugbzc9F--tI"},"outputs":[],"source":["# =========================\n","#  IMPORTS & DEPENDENCIES\n","# =========================\n","\n","!pip install -q openai-whisper pydub requests iso8601 reportlab\n","!apt-get update -qq && apt-get install -y -qq ffmpeg"]},{"cell_type":"markdown","metadata":{"id":"G6H8lDqPq2JK"},"source":["<div style=\"border:2px solid #666;padding:12px;border-radius:8px;background:#F7F7F7\">\n","<h3>Section: Imports & Setup</h3>\n","<p>Core libraries and baseline configuration. Run everything in order using <b>Runtime → Run all</b>.</p>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iZueWnhcXOom"},"outputs":[],"source":["import gc\n","import whisper\n","import json\n","import datetime\n","from pathlib import Path\n","import torch\n","from pydub import AudioSegment\n","import numpy as np\n","import requests\n","import re\n","import iso8601\n","import csv\n","import subprocess\n","from datetime import timedelta\n","from IPython.display import clear_output\n","from tqdm.notebook import tqdm  # For Jupyter/Colab"]},{"cell_type":"markdown","metadata":{"id":"f4WRQKmyq2JL"},"source":["<div style=\"border:2px solid #8E44AD;padding:12px;border-radius:8px;background:#F9F3FF\">\n","<h3>Section: Forum API Fetch</h3>\n","<p>Fetches class metadata (session title, section/schedule), recording time, attendance, voice windows, and timeline events.</p>\n","<ul>\n","  <li>Attendance shows <b>Present</b> (green) and <b>Absent</b> (red).</li>\n","  <li>Graceful fallbacks if some fields are missing.</li>\n","</ul>\n","</div>"]},{"cell_type":"code","source":["# =========================\n","#  CONSTANTS & UTILITIES\n","#  (helpers, regex, spacing, labelers)\n","# =========================\n","\n","def extract_ids_from_curl(curl_text: str):\n","    \"\"\"\n","    Pull class/section/course IDs and the app link from the cURL.\n","    Prefers the Referer app URL; falls back to the API class URL.\n","    Returns dict: {\"course_id\": str|None, \"section_id\": str|None, \"class_id\": str|None, \"class_link\": str}\n","    \"\"\"\n","    # 1) Try Referer header (e.g., https://forum.minerva.edu/app/courses/2933/sections/11209/classes/79183)\n","    ref_match = re.search(r\"-H\\s+['\\\"](?:referer|Referer):\\s*([^'\\\"\\r\\n]+)\", curl_text)\n","    ref = ref_match.group(1).strip() if ref_match else \"\"\n","    class_link = \"\"\n","    course_id = section_id = class_id = None\n","\n","    if ref:\n","        m = re.search(r\"/app/courses/(\\d+)/sections/(\\d+)/classes/(\\d+)\", ref)\n","        if m:\n","            course_id, section_id, class_id = m.group(1), m.group(2), m.group(3)\n","            class_link = ref\n","\n","    # 2) Fallback: any API class URL in the cURL body\n","    if not class_id:\n","        m2 = re.search(r\"/api/v1/class_grader/classes/(\\d+)\", curl_text)\n","        if m2:\n","            class_id = m2.group(1)\n","            class_link = f\"https://forum.minerva.edu/app/classes/{class_id}\"\n","\n","    return {\n","        \"course_id\": course_id,\n","        \"section_id\": section_id,\n","        \"class_id\": class_id,\n","        \"class_link\": class_link\n","    }\n","\n","from contextlib import nullcontext  # at top if not present\n","\n","def download_to_temp(url: str) -> str:\n","    \"\"\"\n","    Download a remote media file (MP3/MP4/WAV/M4A/AAC/OGG) to /content and\n","    return the local path. Works with signed URLs that don't need cookies.\n","    \"\"\"\n","    base = url.split('?', 1)[0]\n","    suffix = Path(base).suffix or \".mp4\"\n","    local_name = f\"/content/input_from_url{suffix}\"\n","    print(f\"Downloading from URL: {url}\")\n","    with requests.get(url, stream=True) as r:\n","        r.raise_for_status()\n","        with open(local_name, \"wb\") as f:\n","            for chunk in r.iter_content(chunk_size=1024 * 1024):\n","                if chunk:\n","                    f.write(chunk)\n","    print(f\"Downloaded URL to: {local_name}\")\n","    return local_name\n","\n","def resolve_audio_input() -> str:\n","    \"\"\"\n","    Ask the user how to provide the audio/video: local upload, Google Drive, or URL.\n","    - local: user uploads in the Colab sidebar then provides a /content/... path\n","    - gdrive: lazily import & mount google.colab.drive, then prompt for Drive path\n","    - url: download file to /content and return the local temp path\n","    \"\"\"\n","    print(\"2) Choose audio source: local  |  gdrive  |  url\")\n","    src = input(\"Source [local/gdrive/url]: \").strip().lower()\n","    clear_output()\n","\n","    if src == \"gdrive\":\n","        print(\"Mounting Google Drive (one-time authorization may be required)...\")\n","        # Lazy import ONLY if user picked Google Drive\n","        from google.colab import drive   # imported here to avoid forcing the dependency otherwise\n","        drive.mount(\"/content/drive\")\n","        print(\"Enter the file path inside Drive (e.g., /content/drive/MyDrive/recordings/lecture.mp4)\")\n","        path = input(\"Drive path: \").strip()\n","        clear_output()\n","        return path\n","\n","    if src == \"url\":\n","        print(\"Paste the direct file URL (signed URLs supported):\")\n","        url = input(\"URL: \").strip()\n","        clear_output()\n","        return download_to_temp(url)\n","\n","    # default → local upload path\n","    print(\"After uploading your file to Colab, enter its path\")\n","    print(\"   (Typically this will be '/content/your_file.mp3' or '/content/your_file.mp4')\")\n","    print()\n","    print(\"‼️  Wait for the upload to finish before submitting its path.\")\n","    print(\"   Track progress in the bottom-left corner.\")\n","    print()\n","    path = input(\"Path: \").strip()\n","    clear_output()\n","    return path\n","\n","def free_cuda_mem():\n","    \"\"\"Safely clear CUDA cache and trigger Python GC.\"\"\"\n","    try:\n","        if torch.cuda.is_available():\n","            torch.cuda.empty_cache()\n","    except Exception:\n","        pass\n","    try:\n","        gc.collect()\n","    except Exception:\n","        pass\n","\n","def resolve_output_destination() -> str:\n","    \"\"\"\n","    Ask where to save outputs (PDF/CSV): local folder or Google Drive folder.\n","    Lazily mounts Drive only if chosen. Ensures the folder exists.\n","    Returns an absolute folder path.\n","    \"\"\"\n","    print(\"Where should I save the outputs? local  |  gdrive\")\n","    dest = input(\"Destination [local/gdrive]: \").strip().lower()\n","    clear_output()\n","\n","    if dest == \"gdrive\":\n","        # Lazy import/mount only when needed\n","        from google.colab import drive\n","        print(\"Mounting Google Drive...\")\n","        drive.mount(\"/content/drive\")\n","        print(\"Enter a Drive folder (e.g., /content/drive/MyDrive/Transcripts)\")\n","        out_dir = input(\"Drive folder: \").strip()\n","        clear_output()\n","        if not out_dir:\n","            out_dir = \"/content/drive/MyDrive\"\n","        Path(out_dir).mkdir(parents=True, exist_ok=True)\n","        return out_dir\n","\n","    # default: local\n","    print(\"Enter a local folder (press Enter for /content)\")\n","    out_dir = input(\"Local folder: \").strip() or \"/content\"\n","    clear_output()\n","    Path(out_dir).mkdir(parents=True, exist_ok=True)\n","    return out_dir"],"metadata":{"id":"ZBI8zO3oC7nU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dwFqcebq2JL"},"source":["<div style=\"border:2px solid #444;padding:12px;border-radius:8px;background:#FBFBFB\">\n","<h3>Section: User Prompts</h3>\n","<p>Paste your Forum cURL, choose input source (local / Google Drive / direct URL), choose output destination (local / Google Drive), and set privacy (names / ids / both).</p>\n","<ul>\n","  <li><b>Class ID</b> is auto-detected from your cURL.</li>\n","  <li><b>Direct URL</b> downloads the media automatically.</li>\n","  <li>Outputs go to the folder you select, regardless of input source.</li>\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zz_o4ed-Unr8"},"outputs":[],"source":["# =========================\n","#  USER PROMPTS / UI\n","#  (paste cURL, choose source, output destination, privacy)\n","# =========================\n","\n","print(\"1) Paste your Forum cURL (right-click in Chrome DevTools → Copy as cURL):\")\n","raw_curl = input().strip()\n","clear_output()\n","\n","# Auto-derive Class ID (fallback to API URL if Referer is missing)\n","_ids = extract_ids_from_curl(raw_curl)\n","CLASS_ID = _ids.get(\"class_id\") or (re.search(r\"/api/v1/class_grader/classes/(\\d+)\", raw_curl).group(1)\n","                                    if re.search(r\"/api/v1/class_grader/classes/(\\d+)\", raw_curl) else None)\n","if not CLASS_ID:\n","    raise ValueError(\n","        \"Could not extract Class ID from your cURL. \"\n","        \"Open the class page and copy a request that includes a Referer like \"\n","        \"https://forum.minerva.edu/app/courses/.../sections/.../classes/<ID>, \"\n","        \"or a class API URL.\"\n","    )\n","\n","# NEW: unified input selection (local / Google Drive / direct URL)\n","AUDIO_PATH = resolve_audio_input()\n","\n","# NEW: choose where outputs (PDF/CSV) will be saved\n","OUTPUT_DIR = resolve_output_destination()\n","\n","print(\"3) Student name privacy\")\n","print(\"   Type one of: names  (show names)  |  ids  (anonymize to IDs)  |  both  (generate both)\")\n","PRIVACY_MODE = input(\"Privacy mode [names/ids/both]: \").strip().lower()\n","if PRIVACY_MODE not in (\"names\", \"ids\", \"both\"):\n","    PRIVACY_MODE = \"names\"\n","clear_output()\n","\n","print(\"Thank you! Here's what you provided:\\n\")\n","print(f\"Class ID: {CLASS_ID}\")\n","print(f\"Audio Path: {AUDIO_PATH}\")\n","print(f\"Outputs Folder: {OUTPUT_DIR}\")\n","print(f\"Privacy Mode: {PRIVACY_MODE}\")\n","print()\n","print(\"Starting the transcript generation process...\")\n","print(\"⏳ Expect this to take about 15 minutes (varies with file length)\")"]},{"cell_type":"markdown","metadata":{"id":"OMsQOpqjq2JM"},"source":["<div style=\"border:2px solid #2E86C1;padding:12px;border-radius:8px;background:#F3F9FE\">\n","<h3>Section: Audio Prep & Transcription</h3>\n","<p>Validates/normalizes audio (MP3/MP4/WAV/M4A/AAC/OGG), converts to a Whisper-optimized WAV, and transcribes long files in chunks.</p>\n","<ul>\n","  <li>Uses <code>torch.amp.autocast('cuda', ...)</code> (no deprecation warnings).</li>\n","  <li>Fixes common text issues (glued sentences, spacing).</li>\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DASfAmyYPzWu"},"outputs":[],"source":["class AudioPreprocessor:\n","    @staticmethod\n","    def validate_and_fix_file(file_path: str) -> str:\n","        \"\"\"\n","        Validates and preprocesses audio files for optimal transcription.\n","        For MP4 files, first converts to MP3 as an intermediate step.\n","        \"\"\"\n","        print(f\"Validating file: {file_path}\")\n","        if not Path(file_path).exists():\n","            raise FileNotFoundError(f\"File not found: {file_path}\")\n","\n","        try:\n","            # If MP4, convert to MP3 (more tolerant), then to 16kHz mono WAV\n","            if file_path.lower().endswith('.mp4'):\n","                print(f\"Converting MP4 to MP3 (intermediate step)...\")\n","                mp3_path = file_path.rsplit('.', 1)[0] + '.mp3'\n","                result = subprocess.run([\n","                    'ffmpeg', '-y', '-v', 'warning', '-xerror',\n","                    '-i', file_path, '-vn',\n","                    '-acodec', 'libmp3lame', '-ar', '44100', '-ab', '192k', '-f', 'mp3',\n","                    mp3_path\n","                ], capture_output=True, text=True, check=False)\n","\n","                if result.returncode == 0 and Path(mp3_path).exists() and Path(mp3_path).stat().st_size > 0:\n","                    print(f\"Successfully converted to MP3: {mp3_path}\")\n","                    return AudioPreprocessor._convert_to_whisper_wav(mp3_path)\n","                else:\n","                    print(f\"MP3 conversion failed with error: {result.stderr}\")\n","                    return AudioPreprocessor._python_extract_audio(file_path)\n","\n","            # Common audio formats → Whisper WAV\n","            elif file_path.lower().endswith(('.mp3', '.m4a', '.aac', '.ogg')):\n","                print(f\"Converting audio file to optimized WAV format...\")\n","                return AudioPreprocessor._convert_to_whisper_wav(file_path)\n","\n","            elif file_path.lower().endswith('.wav'):\n","                print(f\"File is already in WAV format: {file_path}\")\n","                return file_path\n","\n","            else:\n","                raise ValueError(f\"Unsupported file format: {file_path}. Please upload MP3, MP4, WAV, or other common audio/video format.\")\n","\n","        except Exception as e:\n","            print(f\"Error during file processing: {str(e)}\")\n","            raise\n","\n","    @staticmethod\n","    def _convert_to_whisper_wav(audio_path: str) -> str:\n","        \"\"\"Convert any audio file to WAV format optimized for Whisper (16kHz mono, s16le).\"\"\"\n","        wav_path = audio_path.rsplit('.', 1)[0] + '.wav'\n","        try:\n","            subprocess.run([\n","                'ffmpeg', '-y', '-i', audio_path,\n","                '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1',\n","                wav_path\n","            ], capture_output=True, text=True, check=True)\n","            print(f\"Successfully converted to Whisper-optimized WAV: {wav_path}\")\n","            return wav_path\n","        except subprocess.CalledProcessError as e:\n","            print(f\"WAV conversion failed. ffmpeg error: {e.stderr}\")\n","            raise RuntimeError(f\"Failed to convert {audio_path} to WAV format\")\n","\n","    @staticmethod\n","    def _python_extract_audio(file_path: str) -> str:\n","        \"\"\"Fallback extraction using PyDub when ffmpeg CLI fails.\"\"\"\n","        print(\"Attempting Python-based audio extraction...\")\n","        wav_path = file_path.rsplit('.', 1)[0] + '_extracted.wav'\n","        try:\n","            audio = AudioSegment.from_file(file_path).set_frame_rate(16000).set_channels(1).set_sample_width(2)\n","            audio.export(wav_path, format=\"wav\")\n","            if Path(wav_path).exists() and Path(wav_path).stat().st_size > 0:\n","                print(f\"Successfully extracted audio using Python: {wav_path}\")\n","                return wav_path\n","        except Exception as e:\n","            print(f\"Python audio extraction failed: {str(e)}\")\n","\n","        print(\"Attempting direct binary extraction...\")\n","        try:\n","            binary_wav_path = file_path.rsplit('.', 1)[0] + '_binary.wav'\n","            result = subprocess.run([\n","                'ffmpeg', '-y',\n","                '-f', 'lavfi', '-i', f\"movie={file_path}[out+audio]\",\n","                '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1',\n","                binary_wav_path\n","            ], capture_output=True, text=True, check=False)\n","\n","            if result.returncode == 0 and Path(binary_wav_path).exists() and Path(binary_wav_path).stat().st_size > 0:\n","                print(f\"Binary extraction successful: {binary_wav_path}\")\n","                return binary_wav_path\n","        except Exception as e2:\n","            print(f\"Binary extraction failed: {str(e2)}\")\n","\n","        raise RuntimeError(\"All audio extraction methods failed. Please convert the file manually before uploading.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAdjGA9VVV_2"},"outputs":[],"source":["class TranscriptionProcessor:\n","    \"\"\"\n","    Chunked Whisper transcription with GPU-friendly settings.\n","    Splits long audio into ~4-hour segments, transcribes, and stitches results.\n","\n","    Args:\n","        segment_length (int): Segment length in seconds (default ~4 hours).\n","        model_name (str): Whisper model name to load.\n","    \"\"\"\n","    def __init__(self, segment_length: int = 14_400, model_name: str = \"medium\"):\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        print(f\"Using device: {self.device}\")\n","\n","        if self.device == \"cuda\":\n","            # CUDA perf tweaks\n","            torch.backends.cuda.matmul.allow_tf32 = True\n","            torch.backends.cudnn.benchmark = True\n","            torch.backends.cudnn.allow_tf32 = True\n","            torch.backends.cudnn.deterministic = False\n","            torch.cuda.empty_cache()\n","            # Be careful with this fraction in multi-process environments\n","            try:\n","                torch.cuda.set_per_process_memory_fraction(0.9)\n","            except Exception as e:\n","                print(f\"Warning: could not set memory fraction: {e}\")\n","\n","        print(\"Loading Whisper model...\")\n","        self.model = whisper.load_model(model_name).to(self.device)\n","        if self.device == \"cuda\":\n","            # Use FP16 on GPU\n","            self.model = self.model.half()\n","\n","        self.segment_length = int(segment_length)\n","\n","    def transcribe(self, audio_path: str, class_id: str) -> str | None:\n","        \"\"\"\n","        Transcribe `audio_path` into /content/session_{class_id}_transcript.json and return that path.\n","\n","        Args:\n","            audio_path (str): Path to an audio/video file supported by pydub/ffmpeg.\n","            class_id (str): Identifier used to name the output transcript.\n","\n","        Returns:\n","            str | None: Path to the resulting JSON transcript, or None if nothing was transcribed.\n","        \"\"\"\n","        print(\"Processing audio to generate transcript JSON...\")\n","        try:\n","            # Load audio\n","            audio = AudioSegment.from_file(audio_path)\n","            total_duration = len(audio) / 1000.0  # seconds (float)\n","            print(f\"Total duration: {timedelta(seconds=int(total_duration))}\")\n","\n","            all_segments: list[dict] = []\n","            segment_times = range(0, int(total_duration), self.segment_length)\n","\n","            for start_time in tqdm(segment_times, desc=\"Processing segments\", unit=\"segment\"):\n","                # Compute this segment's end (in seconds)\n","                remaining = total_duration - start_time\n","                duration = min(self.segment_length, remaining)\n","\n","                # Slice pydub audio in milliseconds (cast to int to be safe)\n","                start_ms = int(start_time * 1000)\n","                end_ms = int((start_time + duration) * 1000)\n","                segment = audio[start_ms:end_ms]\n","\n","                # Export temp wav for Whisper\n","                temp_path = f\"/content/temp_segment_{start_time}.wav\"\n","                segment.export(temp_path, format=\"wav\")\n","\n","                try:\n","                    # Use autocast only on CUDA; nullcontext() on CPU\n","                    cast_ctx = torch.amp.autocast(\"cuda\") if self.device == \"cuda\" else nullcontext()\n","                    with cast_ctx:\n","                        result = self.model.transcribe(\n","                            temp_path,\n","                            word_timestamps=True,\n","                            language=\"en\",\n","                            task=\"transcribe\",\n","                            fp16=(self.device == \"cuda\"),\n","                            condition_on_previous_text=True,\n","                            initial_prompt=\"This is a university lecture.\"\n","                        )\n","\n","                        # Gather segments with global (shifted) times\n","                        for seg in result.get(\"segments\", []):\n","                            seg_start = float(seg.get(\"start\", 0.0)) + start_time\n","                            seg_end = float(seg.get(\"end\", 0.0)) + start_time\n","\n","                            words = []\n","                            for w in seg.get(\"words\", []) or []:\n","                                words.append({\n","                                    \"word\": str(w.get(\"word\", \"\")).strip(),\n","                                    \"start\": float(w.get(\"start\", 0.0)) + start_time,\n","                                    \"end\": float(w.get(\"end\", 0.0)) + start_time\n","                                })\n","\n","                            all_segments.append({\n","                                \"start\": seg_start,\n","                                \"end\": seg_end,\n","                                \"text\": normalize_sentence_spacing(str(seg.get(\"text\", \"\")).strip()),\n","                                \"words\": words\n","                            })\n","\n","                except Exception as segment_error:\n","                    print(f\"Error processing segment at {start_time}s: {segment_error}\")\n","                    continue\n","                finally:\n","                    # Cleanup temp file and free GPU mem\n","                    try:\n","                        Path(temp_path).unlink(missing_ok=True)\n","                    except Exception as e:\n","                        print(f\"Warning: Failed to delete temp file {temp_path}: {e}\")\n","                    if self.device == \"cuda\":\n","                        torch.cuda.empty_cache()\n","                        gc.collect()\n","\n","            if not all_segments:\n","                print(\"Warning: No segments were successfully transcribed!\")\n","                return None\n","\n","            # Sort by start time and write JSON\n","            transcript_path = f\"/content/session_{class_id}_transcript.json\"\n","            with open(transcript_path, \"w\", encoding=\"utf-8\") as f:\n","                json.dump({\"segments\": sorted(all_segments, key=lambda x: x[\"start\"])}, f, indent=2)\n","\n","            print(f\"\\nTranscript JSON saved to: {transcript_path}\")\n","            return transcript_path\n","\n","        except Exception as e:\n","            print(f\"Error in transcription process: {e}\")\n","            raise"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFRSWCdOSfo_"},"outputs":[],"source":["def clean_curl(curl_string):\n","    \"\"\"Parse a DevTools cURL and return an HTTP headers dict including Cookie (if present).\"\"\"\n","    headers = {}\n","    header_matches = re.findall(r\"-H ['\\\"](.*?): (.*?)['\\\"]\", curl_string)\n","    for name, value in header_matches:\n","        headers[name] = value\n","    cookie_match = re.search(r\"-b ['\\\"](.*?)['\\\"]\", curl_string)\n","    if cookie_match:\n","        headers['Cookie'] = cookie_match.group(1)\n","    return headers\n","\n","def get_forum_events(class_id, headers):\n","    \"\"\"\n","    Fetch class meta + class events from Forum and normalize.\n","\n","    Also extracts a student attendance list (present/absent).\n","    \"\"\"\n","    print(\"Fetching class and event data from Forum...\")\n","\n","    # ---- Class meta ----\n","    class_url = f'https://forum.minerva.edu/api/v1/class_grader/classes/{class_id}'\n","    print(f\"Requesting class data from: {class_url}\")\n","    r = requests.get(class_url, headers=headers)\n","    if r.status_code != 200:\n","        print(f\"Error accessing class data. Status code: {r.status_code}\\n{r.text}\")\n","        raise RuntimeError(f\"Failed to access class data. Status code: {r.status_code}\")\n","    data = r.json()\n","\n","    session_title = data.get('title') or f\"Session {class_id}\"\n","    course_obj = (data.get('section') or {}).get('course') or {}\n","    course_code  = course_obj.get('course-code', '')\n","    course_title = course_obj.get('title', '')\n","    section_title = (data.get('section') or {}).get('title', '')\n","    class_type = data.get('type', '')\n","    rec = (data.get('recording-sessions') or [{}])[0]\n","    recording_start = rec.get('recording-started')\n","    recording_end   = rec.get('recording-ended')\n","\n","    schedule_guess = ''\n","    if isinstance(section_title, str) and ',' in section_title:\n","        parts = [p.strip() for p in section_title.split(',', 1)]\n","        schedule_guess = parts[1] if len(parts) > 1 else ''\n","\n","    class_meta = {\n","        'session_title': session_title,\n","        'course_code': course_code,\n","        'course_title': course_title,\n","        'section_title': section_title,\n","        'schedule': schedule_guess,\n","        'class_type': class_type,\n","        'recording_start': recording_start,\n","        'recording_end': recording_end,\n","    }\n","\n","    if not recording_start:\n","        raise KeyError(\"No recording-started found in class data\")\n","\n","    # ---- Events ----\n","    events_url = f'https://forum.minerva.edu/api/v1/class_grader/classes/{class_id}/class-events'\n","    print(f\"Requesting events from: {events_url}\")\n","    r = requests.get(events_url, headers=headers)\n","    if r.status_code != 200:\n","        print(f\"Error accessing class events. Status code: {r.status_code}\\n{r.text}\")\n","        raise RuntimeError(f\"Failed to access class events. Status code: {r.status_code}\")\n","    events = r.json()\n","    if not isinstance(events, list):\n","        raise ValueError(\"No valid class events returned from API\")\n","\n","    voice_events = []\n","    timeline_segments = []\n","    ref_time = iso8601.parse_date(recording_start)\n","\n","    for ev in events:\n","        et = ev.get('event-type')\n","        try:\n","            if et == 'voice':\n","                duration_ms = (ev.get('event-data') or {}).get('duration', 0)\n","                duration = duration_ms / 1000.0\n","                if duration >= 1:\n","                    start_time = iso8601.parse_date(ev['start-time'])\n","                    end_time   = iso8601.parse_date(ev['end-time'])\n","                    voice_events.append({\n","                        'start': (start_time - ref_time).total_seconds(),\n","                        'end': (end_time - ref_time).total_seconds(),\n","                        'duration': duration,\n","                        'speaker': {\n","                          'id':        (ev.get('actor') or {}).get('id') or (ev.get('actor') or {}).get('user-id') or ((ev.get('actor') or {}).get('user') or {}).get('id'),\n","                          'first-name': (ev.get('actor') or {}).get('first-name'),\n","                          'last-name':  (ev.get('actor') or {}).get('last-name')\n","                        }\n","                    })\n","            elif et == 'timeline-segment':\n","                start_time = iso8601.parse_date(ev['start-time'])\n","                seg = (ev.get('event-data') or {})\n","                timeline_segments.append({\n","                    'abs_start': ev['start-time'],\n","                    'offset_seconds': (start_time - ref_time).total_seconds(),\n","                    'section': seg.get('timeline-section-title', ''),\n","                    'title':   seg.get('timeline-segment-title', ''),\n","                })\n","        except KeyError:\n","            continue\n","\n","    timeline_segments.sort(key=lambda x: x['offset_seconds'])\n","\n","    # ---- Attendance ----\n","    attendance = []\n","    for cu in (data.get('class-users') or []):\n","        role = (cu.get('role') or '').lower()\n","        if role == 'student':\n","            u = cu.get('user') or {}\n","            first = u.get('first-name', '') or ''\n","            last = u.get('last-name', '') or ''\n","            name = f\"{first} {last}\".strip() or (u.get('preferred-name') or '').strip() or (u.get('first-name') or '').strip()\n","            uid = u.get('id') or u.get('user-id')\n","            absent = bool(cu.get('absent', False))\n","            attendance.append({'id': uid, 'name': name, 'absent': absent})\n","\n","    try:\n","        attendance.sort(key=lambda x: (x['name'] or '').lower())\n","    except Exception:\n","        pass\n","\n","    events_data = {\n","        'class_id': class_id,\n","        'class_meta': class_meta,\n","        'voice_events': voice_events,\n","        'timeline_segments': timeline_segments,\n","        'attendance': attendance\n","    }\n","    temp_events_path = f\"/content/session_{class_id}_events.json\"\n","    with open(temp_events_path, 'w', encoding='utf-8') as f:\n","        json.dump(events_data, f, indent=2)\n","\n","    print(f\"Processed voice events: {len(voice_events)}; timeline segments: {len(timeline_segments)}\")\n","    return events_data\n","\n","# ----------------------------\n","# Utilities\n","# ----------------------------\n","def _fmt_mmss(seconds_float):\n","    if seconds_float is None:\n","        return \"\"\n","    seconds = max(0, int(seconds_float))\n","    m, s = divmod(seconds, 60)\n","    return f\"{m:02d}:{s:02d}\"\n","\n","def _safe_date(date_str):\n","    if not date_str:\n","        return \"\"\n","    try:\n","        return date_str.split('T')[0]\n","    except Exception:\n","        return \"\"\n","\n","def _fmt_dt_hm(dt_str: str) -> str:\n","    \"\"\"YYYY-MM-DD HH:MM TZ from ISO8601; fallback to YYYY-MM-DD.\"\"\"\n","    if not dt_str:\n","        return \"\"\n","    try:\n","        dt = iso8601.parse_date(dt_str)\n","        return dt.strftime(\"%Y-%m-%d %H:%M %Z\")\n","    except Exception:\n","        return _safe_date(dt_str)\n","\n","def soft_break_long_token(s: str, max_run: int = 14) -> str:\n","    if not s:\n","        return s\n","    # use a callable to avoid backslash escapes in the replacement\n","    pat = re.compile(r'(\\S{%d})(?=\\S)' % max_run)\n","    return pat.sub(lambda m: m.group(1) + '\\u200b', s)\n","\n","# --- Text cleanup helper ---\n","\n","def normalize_sentence_spacing(text: str) -> str:\n","    \"\"\"Fix glued sentences & punctuation spacing (respects ellipses), collapse newlines/spaces.\"\"\"\n","    if not text:\n","        return text\n","    # remove zero-widths & non-breaking spaces, collapse newlines\n","    text = re.sub(r'[\\u200B-\\u200D\\uFEFF]', '', text)\n","    text = text.replace('\\u00A0', ' ')\n","    text = re.sub(r'\\s*\\n+\\s*', ' ', text)\n","\n","    # keep ellipses intact but add a space after if glued\n","    text = re.sub(r'(\\.\\.\\.)(?=\\S)', r'\\1 ', text)\n","\n","    # add a space after ., ?, ! when next visible char is a letter or an opening quote/paren\n","    # and NOT a decimal number (next char digit)\n","    text = re.sub(r'(?<!\\.)'              # previous char is not a dot (avoid inside \"...\")\n","                  r'([.!?])'              # sentence end\n","                  r'(?=([\"“\\'(\\[]?[A-Za-z]))'  # next visible char is letter (maybe after quote/paren)\n","                  , r'\\1 ', text)\n","\n","    # optional: add space after : or ; if followed by a letter\n","    text = re.sub(r'([:;])(?=([\"“\\'(\\[]?[A-Za-z]))', r'\\1 ', text)\n","\n","    # de-glue common quote cases like: .“Word  .’Word  .)Word\n","    text = re.sub(r'([.!?][\"”\\')\\]])(?=\\S)', r'\\1 ', text)\n","\n","    # collapse multiple spaces\n","    text = re.sub(r'\\s{2,}', ' ', text)\n","    return text.strip()\n","\n","def label_from_actor(actor: dict, name_mode: str, student_ids: set | None = None) -> str:\n","    \"\"\"Return display label for a speaker based on privacy setting.\"\"\"\n","    if not isinstance(actor, dict):\n","        return \"Professor\"\n","    uid = actor.get('id') or actor.get('user-id') or (actor.get('user') or {}).get('id')\n","    fn  = (actor.get('first-name') or '').strip()\n","    ln  = (actor.get('last-name') or '').strip()\n","    full = f\"{fn} {ln}\".strip()\n","    if name_mode == 'ids':\n","        # anonymize students; if we don't know role, anonymize when in the student set (if provided)\n","        if (student_ids is None and uid is not None) or (student_ids is not None and uid in student_ids):\n","            return str(uid) if uid is not None else \"ID\"\n","    return full or \"Professor\""]},{"cell_type":"markdown","metadata":{"id":"HKzAhuU0q2JN"},"source":["<div style=\"border:2px solid #27AE60;padding:12px;border-radius:8px;background:#F4FBF6\">\n","<h3>Section: Output Compilers (PDF/CSV) & Fallbacks</h3>\n","<p>Builds final PDF/CSV with header (title + section/schedule), then <b>Class ID</b>, <b>Class Date/Time</b>, <b>Class Link</b>, Attendance, Class Events, and an event-grouped transcript.</p>\n","<ul>\n","  <li><b>Privacy:</b> names / ids / both (two sets: <code>_names</code> and <code>_ids</code>).</li>\n","  <li>Outputs saved to your chosen folder (local or Google Drive).</li>\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtDyII9cVXcw"},"outputs":[],"source":["from reportlab.lib import colors\n","from reportlab.lib.pagesizes import letter\n","from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.units import inch\n","\n","def compile_transcript_to_pdf(class_id, headers, name_mode: str = \"names\", file_suffix: str = \"\", output_dir: str = \"/content\"):\n","    \"\"\"\n","    Render the PDF with header, attendance, events, and event-bucketed transcript.\n","    \"\"\"\n","    try:\n","        with open(f\"/content/session_{class_id}_transcript.json\", 'r') as f:\n","            transcript_data = json.load(f)\n","        with open(f\"/content/session_{class_id}_events.json\", 'r') as f:\n","            events_data = json.load(f)\n","\n","        class_meta = events_data.get('class_meta', {})\n","        timeline_segments = events_data.get('timeline_segments', [])\n","        attendance = events_data.get('attendance', [])\n","        student_ids_set = {a.get('id') for a in attendance if a.get('id') is not None}\n","\n","        # Build speaker map from voice windows\n","        speaker_map = {}\n","        for ev in events_data.get('voice_events', []):\n","          speaker_map[(ev['start'], ev['end'])] = ev.get('speaker', {})  # keep dict (has id + names)\n","\n","        def find_speaker_at_time(t):\n","          for (start, end), spk in speaker_map.items():\n","              if start <= t <= end:\n","                  return label_from_actor(spk, name_mode, student_ids_set)\n","          return \"Professor\"\n","\n","\n","        # Combine consecutive segments by same speaker\n","        compiled_entries = []\n","        current = {'speaker': None, 'start_time': None, 'text': [], 'end_time': None}\n","\n","        for seg in transcript_data['segments']:\n","            st, en, tx = seg['start'], seg['end'], seg['text'].strip()\n","            if not tx:\n","                continue\n","            spk = find_speaker_at_time(st)\n","\n","            start_new = False\n","            if not current['speaker']:\n","                start_new = True\n","            elif current['speaker'] != spk:\n","                start_new = True\n","            elif current['end_time'] is not None and st - current['end_time'] > 2:\n","                start_new = True\n","\n","            if start_new:\n","                if current['speaker']:\n","                    compiled_entries.append(current)\n","                current = {'speaker': spk, 'start_time': st, 'text': [tx], 'end_time': en}\n","            else:\n","                current['text'].append(tx)\n","                current['end_time'] = en\n","\n","        if current['speaker']:\n","            compiled_entries.append(current)\n","\n","        # Styles\n","        styles = getSampleStyleSheet()\n","        contribution_style = ParagraphStyle(\n","            'ContributionStyle', parent=styles['Normal'],\n","            fontName='Helvetica', fontSize=10, leading=12, wordWrap='CJK'\n","        )\n","        header_style = ParagraphStyle(\n","            'HeaderStyle', parent=styles['Normal'],\n","            fontName='Helvetica-Bold', fontSize=12, textColor=colors.whitesmoke, alignment=1\n","        )\n","        speaker_style = ParagraphStyle(\n","            'SpeakerStyle', parent=styles['Normal'],\n","            fontName='Helvetica', fontSize=10, leading=12, wordWrap='CJK'\n","        )\n","\n","        # PDF scaffold\n","        output_path = str(Path(output_dir) / f\"session_{class_id}_transcript{file_suffix}.pdf\")\n","        doc = SimpleDocTemplate(output_path, pagesize=letter,\n","                                rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=72)\n","        elements = []\n","\n","        # ====== HEADER ======\n","        session_line = class_meta.get('session_title') or f\"Session {class_id}\"\n","        elements.append(Paragraph(session_line, styles['Title']))\n","\n","        # Only the sec_sched value, centered\n","        sec_sched = class_meta.get('section_title', '') or class_meta.get('schedule', '')\n","        if sec_sched:\n","            centered_info_style = ParagraphStyle('CenteredInfo', parent=styles['Heading3'], alignment=1)\n","            elements.append(Paragraph(sec_sched, centered_info_style))\n","            elements.append(Spacer(1, 12))\n","        else:\n","            elements.append(Spacer(1, 12))\n","\n","        # Left-aligned: labeled class id, date/time, and class link from cURL Referer\n","        left_info_style = ParagraphStyle('LeftInfo', parent=styles['Normal'], alignment=0)\n","        class_datetime = _fmt_dt_hm(class_meta.get('recording_start'))\n","\n","        # Prefer the Referer header for the app URL (e.g., https://forum.minerva.edu/app/courses/.../classes/...)\n","        ref = (headers.get('referer') or headers.get('Referer') or '').strip()\n","        m = re.search(r'https://forum\\.minerva\\.edu/app/[^\\s\"\\']+', ref)\n","        class_link = m.group(0) if m else f\"https://forum.minerva.edu/app/classes/{class_id}\"\n","\n","        elements.append(Paragraph(f\"<b>Class ID:</b> {class_id}\", left_info_style))\n","        elements.append(Paragraph(f\"<b>Class Date/Time:</b> {class_datetime}\", left_info_style))\n","        elements.append(Paragraph(f'<b>Class Link:</b> <a href=\"{class_link}\">{class_link}</a>', left_info_style))\n","        elements.append(Spacer(1, 12))  # blank line before next section\n","\n","        # ====== ATTENDANCE TABLE ======\n","        attendance = events_data.get('attendance', [])\n","        if attendance:\n","            elements.append(Paragraph(\"Attendance\", styles['Heading3']))\n","            att_rows = [[Paragraph('Student', header_style), Paragraph('Status', header_style)]]\n","            for a in attendance:\n","              status = 'Absent' if a.get('absent') else 'Present'\n","              display_student = (f\"ID {a.get('id')}\" if name_mode == 'ids' and a.get('id') is not None else a.get('name',''))\n","              att_rows.append([Paragraph(soft_break_long_token(display_student, 14), speaker_style), status])\n","            att_table = Table(att_rows, colWidths=[4.5*inch, 1.5*inch], repeatRows=1)\n","            att_style = TableStyle([\n","                ('BACKGROUND', (0,0), (-1,0), colors.grey),\n","                ('TEXTCOLOR', (0,0), (-1,0), colors.whitesmoke),\n","                ('ALIGN', (0,0), (-1,0), 'CENTER'),\n","                ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n","                ('FONTNAME', (0,1), (-1,-1), 'Helvetica'),\n","                ('FONTSIZE', (0,1), (-1,-1), 10),\n","                ('VALIGN', (0,0), (-1,-1), 'TOP'),\n","                ('GRID', (0,0), (-1,-1), 1, colors.black),\n","                ('LEFTPADDING', (0,0), (-1,-1), 6),\n","                ('RIGHTPADDING', (0,0), (-1,-1), 6),\n","                ('TOPPADDING', (0,0), (-1,-1), 3),\n","                ('BOTTOMPADDING', (0,0), (-1,-1), 3),\n","            ])\n","            for i, a in enumerate(attendance, start=1):\n","                color = colors.red if a.get('absent') else colors.green\n","                att_style.add('TEXTCOLOR', (1,i), (1,i), color)\n","            att_table.setStyle(att_style)\n","            elements.append(att_table)\n","            elements.append(Spacer(1, 18))\n","\n","        # ====== CLASS EVENTS TABLE (wrapped cells) ======\n","        if timeline_segments:\n","            elements.append(Paragraph(\"Class Events\", styles['Heading3']))\n","            events_data_rows = [[Paragraph('Time', header_style),\n","                                Paragraph('Section', header_style),\n","                                Paragraph('Event', header_style)]]\n","            for seg in timeline_segments:\n","                sec_txt = soft_break_long_token(seg.get('section', '') or '', 14)\n","                evt_txt = soft_break_long_token(seg.get('title', '') or '', 14)\n","                events_data_rows.append([\n","                    _fmt_mmss(seg.get('offset_seconds')),\n","                    Paragraph(sec_txt, contribution_style),\n","                    Paragraph(evt_txt, contribution_style)\n","                ])\n","            # slightly wider Event column to reduce wrapping pressure\n","            events_table = Table(events_data_rows, colWidths=[0.85*inch, 2.10*inch, 4.05*inch], repeatRows=1)\n","            events_table.setStyle(TableStyle([\n","                ('BACKGROUND', (0,0), (-1,0), colors.grey),\n","                ('TEXTCOLOR', (0,0), (-1,0), colors.whitesmoke),\n","                ('ALIGN', (0,0), (-1,0), 'CENTER'),\n","                ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n","                ('FONTNAME', (0,1), (-1,-1), 'Helvetica'),\n","                ('FONTSIZE', (0,1), (-1,-1), 10),\n","                ('VALIGN', (0,0), (-1,-1), 'TOP'),\n","                ('GRID', (0,0), (-1,-1), 1, colors.black),\n","                ('LEFTPADDING', (0,0), (-1,-1), 6),\n","                ('RIGHTPADDING', (0,0), (-1,-1), 6),\n","                ('TOPPADDING', (0,0), (-1,-1), 3),\n","                ('BOTTOMPADDING', (0,0), (-1,-1), 3),\n","            ]))\n","            elements.append(events_table)\n","            elements.append(Spacer(1, 18))\n","\n","\n","        # ====== TRANSCRIPT: ONLY BREAK ON NEW CLASS EVENTS ======\n","        elements.append(Paragraph(\"Transcript\", styles['Heading3']))\n","        elements.append(Spacer(1, 6))\n","\n","        # Flatten entries to printable rows\n","        all_items = []\n","        for entry in compiled_entries:\n","            text = ' '.join(entry['text']).strip()\n","            text = normalize_sentence_spacing(text)\n","            if text in ['...', '.', '', 'Mm-hmm.'] or len(text) < 3:\n","                continue\n","            timestamp = _fmt_mmss(entry['start_time'])\n","\n","\n","            max_chars_per_chunk = 500\n","            sentences = text.split('. ')\n","            chunks, curr = [], \"\"\n","            for s in sentences:\n","                candidate = (curr + s + '. ').strip() if curr else (s + '. ')\n","                if len(candidate) <= max_chars_per_chunk:\n","                    curr = candidate\n","                else:\n","                    if curr: chunks.append(curr.strip())\n","                    curr = s + '. '\n","            if curr: chunks.append(curr.strip())\n","\n","            for i, chunk in enumerate(chunks or [text]):\n","                display_ts = \"(cont.)\" if i > 0 else timestamp\n","                all_items.append({\n","                    'start_time': entry['start_time'],\n","                    'end_time': entry['end_time'],\n","                    'timestamp': display_ts,\n","                    'speaker': entry['speaker'],\n","                    'text': chunk\n","                })\n","\n","        all_items.sort(key=lambda x: x['start_time'])\n","\n","        # Build event windows; include preamble\n","        seg_windows = []\n","        if timeline_segments:\n","            first_start = max(0, (timeline_segments[0].get('offset_seconds') or 0))\n","            if first_start > 0:\n","                seg_windows.append({'start': 0, 'end': first_start, 'label': f\"{_fmt_mmss(0)} — Before first event\"})\n","            for idx, seg in enumerate(timeline_segments):\n","                start = max(0, (seg.get('offset_seconds') or 0))\n","                end = (timeline_segments[idx+1].get('offset_seconds') if idx+1 < len(timeline_segments) else float('inf')) or float('inf')\n","                label_bits = []\n","                if seg.get('section'): label_bits.append(seg['section'])\n","                if seg.get('title'): label_bits.append(seg['title'])\n","                label_core = ' · '.join(label_bits) if label_bits else 'Event'\n","                seg_windows.append({'start': start, 'end': end, 'label': f\"{_fmt_mmss(start)} — {label_core}\"})\n","        else:\n","            seg_windows.append({'start': 0, 'end': float('inf'), 'label': \"Transcript\"})\n","\n","        for win in seg_windows:\n","            bucket = [it for it in all_items if win['start'] <= it['start_time'] < win['end']]\n","            if not bucket:\n","                continue\n","\n","            # Event heading inside transcript\n","            elements.append(Paragraph(win['label'], styles['Heading4']))\n","            elements.append(Spacer(1, 4))\n","\n","            # Single table for this event; ReportLab splits across pages automatically.\n","            data = [[Paragraph('Time', header_style),\n","                     Paragraph('Speaker', header_style),\n","                     Paragraph('Contribution', header_style)]]\n","            for item in bucket:\n","                spk_txt = soft_break_long_token(item['speaker'], 14)\n","                data.append([item['timestamp'], Paragraph(spk_txt, speaker_style), Paragraph(normalize_sentence_spacing(item['text']), contribution_style)])\n","\n","            table = Table(data, colWidths=[0.75*inch, 2.2*inch, 4.25*inch], repeatRows=1)\n","            table.setStyle(TableStyle([\n","                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n","                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n","                ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n","                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","                ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n","                ('FONTSIZE', (0, 1), (-1, -1), 10),\n","                ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n","                ('GRID', (0, 0), (-1, -1), 1, colors.black),\n","                ('LEFTPADDING', (0, 0), (-1, -1), 6),\n","                ('RIGHTPADDING', (0, 0), (-1, -1), 6),\n","                ('TOPPADDING', (0, 0), (-1, -1), 3),\n","                ('BOTTOMPADDING', (0, 0), (-1, -1), 3),\n","            ]))\n","            elements.append(table)\n","            elements.append(Spacer(1, 16))\n","\n","        doc.build(elements)\n","        print(f\"Created PDF transcript: {output_path}\")\n","        return output_path\n","\n","    except Exception as e:\n","        print(f\"Error processing transcript: {str(e)}\")\n","        raise e\n","\n","def compile_transcript_to_csv(class_id, headers, name_mode: str = \"names\", file_suffix: str = \"\", output_dir: str = \"/content\"):\n","    \"\"\"\n","    CSV:\n","      - Header\n","      - Attendance\n","      - Class Events\n","      - Transcript with event headers\n","    \"\"\"\n","    try:\n","        with open(f\"/content/session_{class_id}_transcript.json\", 'r') as f:\n","            transcript_data = json.load(f)\n","        with open(f\"/content/session_{class_id}_events.json\", 'r') as f:\n","            events_data = json.load(f)\n","\n","        class_meta = events_data.get('class_meta', {})\n","        timeline_segments = events_data.get('timeline_segments', [])\n","        attendance = events_data.get('attendance', [])\n","        student_ids_set = {a.get('id') for a in attendance if a.get('id') is not None}\n","\n","        # Speaker mapping from voice events\n","        speaker_map = {}\n","        for ev in events_data.get('voice_events', []):\n","          speaker_map[(ev['start'], ev['end'])] = ev.get('speaker', {})\n","\n","\n","        def find_speaker_at_time(t):\n","          for (start, end), spk in speaker_map.items():\n","              if start <= t <= end:\n","                  return label_from_actor(spk, name_mode, student_ids_set)\n","          return \"Professor\"\n","\n","        # Combine segments by speaker\n","        compiled_entries = []\n","        current = {'speaker': None, 'start_time': None, 'text': [], 'end_time': None}\n","        for seg in transcript_data['segments']:\n","            st, en, tx = seg['start'], seg['end'], seg['text'].strip()\n","            if not tx:\n","                continue\n","            spk = find_speaker_at_time(st)\n","\n","            start_new = False\n","            if not current['speaker']:\n","                start_new = True\n","            elif current['speaker'] != spk:\n","                start_new = True\n","            elif current['end_time'] is not None and st - current['end_time'] > 2:\n","                start_new = True\n","\n","            if start_new:\n","                if current['speaker']:\n","                    compiled_entries.append(current)\n","                current = {'speaker': spk, 'start_time': st, 'text': [tx], 'end_time': en}\n","            else:\n","                current['text'].append(tx)\n","                current['end_time'] = en\n","        if current['speaker']:\n","            compiled_entries.append(current)\n","\n","        # Flatten → rows\n","        all_items = []\n","        for entry in compiled_entries:\n","            text = normalize_sentence_spacing(' '.join(entry['text']).strip())\n","            if text in ['...', '.', '', 'Mm-hmm.'] or len(text) < 3:\n","                continue\n","            timestamp = _fmt_mmss(entry['start_time'])\n","            all_items.append({\n","                'timestamp': timestamp,\n","                'speaker': entry['speaker'],\n","                'text': text,\n","                'start_time': entry['start_time'],\n","                'end_time': entry['end_time']\n","            })\n","        all_items.sort(key=lambda x: x['start_time'])\n","\n","        # Build event windows (with preamble)\n","        segmented_rows = []\n","        seg_windows = []\n","        if timeline_segments:\n","            first_start = max(0, (timeline_segments[0].get('offset_seconds') or 0))\n","            if first_start > 0:\n","                seg_windows.append({'start': 0, 'end': first_start, 'label': f\"{_fmt_mmss(0)} — Before first event\"})\n","            for idx, seg in enumerate(timeline_segments):\n","                start = max(0, (seg.get('offset_seconds') or 0))\n","                end = (timeline_segments[idx+1].get('offset_seconds') if idx+1 < len(timeline_segments) else float('inf')) or float('inf')\n","                bits = []\n","                if seg.get('section'): bits.append(seg['section'])\n","                if seg.get('title'):   bits.append(seg['title'])\n","                label = f\"{_fmt_mmss(start)} — \" + (' / '.join(bits) if bits else 'Event')\n","                seg_windows.append({'start': start, 'end': end, 'label': label})\n","        else:\n","            seg_windows.append({'start': 0, 'end': float('inf'), 'label': \"Transcript\"})\n","\n","        for win in seg_windows:\n","            bucket = [it for it in all_items if win['start'] <= it['start_time'] < win['end']]\n","            if not bucket:\n","                continue\n","            segmented_rows.append({'timestamp': '', 'speaker': '', 'text': f\"--- {win['label']} ---\"})\n","            segmented_rows.extend(bucket)\n","\n","        all_items = segmented_rows or all_items\n","\n","        # Write CSV\n","        output_path = str(Path(output_dir) / f\"session_{class_id}_transcript{file_suffix}.csv\")\n","        with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n","            w = csv.writer(csvfile)\n","\n","            # --- Header block ---\n","            w.writerow([\"Session\", class_meta.get('session_title','')])\n","            sec_sched = class_meta.get('section_title') or class_meta.get('schedule') or ''\n","            if sec_sched:\n","                w.writerow([sec_sched])\n","            w.writerow([])  # blank line (matches PDF spacing)\n","\n","            # class id, class date/time, class link (each on its own labeled line)\n","            class_datetime = _fmt_dt_hm(class_meta.get('recording_start'))\n","            ref = (headers.get('referer') or headers.get('Referer') or '').strip()\n","            m = re.search(r'https://forum\\.minerva\\.edu/app/[^\\s\"\\']+', ref)\n","            class_link = m.group(0) if m else f\"https://forum.minerva.edu/app/classes/{class_id}\"\n","\n","            w.writerow([f\"Class ID: {class_id}\"])\n","            w.writerow([f\"Class Date/Time: {class_datetime}\"])\n","            w.writerow([f\"Class Link: {class_link}\"])\n","            w.writerow([])  # blank line before Attendance / Events\n","\n","            # --- Attendance ---\n","            attendance = events_data.get('attendance', [])\n","            if attendance:\n","                w.writerow([\"Attendance\"])\n","                w.writerow([\"Student\", \"Status\"])\n","                for a in attendance:\n","                    label = (str(a['id']) if (name_mode == \"ids\" and a.get('id')) else a.get('name',''))\n","                    w.writerow([label, \"Absent\" if a.get('absent') else \"Present\"])\n","                w.writerow([])\n","\n","            # --- Class Events (timeline) ---\n","            if timeline_segments:\n","                w.writerow([\"Class Events\"])\n","                w.writerow([\"Time\", \"Section\", \"Event\"])\n","                for seg in timeline_segments:\n","                    w.writerow([\n","                        _fmt_mmss(seg.get('offset_seconds')),\n","                        seg.get('section',''),\n","                        seg.get('title','')\n","                    ])\n","                w.writerow([])\n","\n","            # --- Transcript table ---\n","            w.writerow(['Time', 'Speaker', 'Contribution'])\n","            for item in all_items:\n","                w.writerow([\n","                    item['timestamp'],\n","                    item['speaker'],\n","                    item['text']\n","                ])\n","\n","        print(f\"Created CSV transcript: {output_path}\")\n","        return output_path\n","\n","    except Exception as e:\n","        print(f\"Error creating CSV transcript: {str(e)}\")\n","        return None\n","\n","def create_simplified_csv(class_id, transcript_path, output_dir: str = \"/content\"):\n","    \"\"\"\n","    Fallback CSV: just time + text (no speakers/events).\n","    \"\"\"\n","    try:\n","        with open(f\"/content/session_{class_id}_transcript.json\", 'r') as f:\n","            transcript_data = json.load(f)\n","\n","        output_path = str(Path(output_dir) / f\"session_{class_id}_transcript_simple.csv\")\n","        with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n","            writer = csv.writer(csvfile)\n","            writer.writerow(['Time', 'Text'])\n","            for seg in transcript_data['segments']:\n","                minutes = int(seg['start'] // 60)\n","                seconds = int(seg['start'] % 60)\n","                timestamp = f\"{minutes:02d}:{seconds:02d}\"\n","                writer.writerow([timestamp, normalize_sentence_spacing(seg.get('text', ''))])\n","\n","        print(f\"Created simplified CSV transcript: {output_path}\")\n","        return output_path\n","    except Exception as e:\n","        print(f\"Error creating simplified CSV transcript: {str(e)}\")\n","        return None\n","\n","def create_simplified_transcript(class_id, transcript_path, output_dir: str = \"/content\"):\n","    \"\"\"\n","    Fallback PDF: no events, no speakers; includes minimal title.\n","    \"\"\"\n","    try:\n","        from reportlab.lib import colors\n","        from reportlab.lib.pagesizes import letter\n","        from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n","        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","        from reportlab.lib.units import inch\n","        import json\n","        from datetime import datetime\n","\n","        with open(f\"/content/session_{class_id}_transcript.json\", 'r') as f:\n","            transcript_data = json.load(f)\n","\n","        styles = getSampleStyleSheet()\n","        text_style = ParagraphStyle('TextStyle', parent=styles['Normal'],\n","                                    fontName='Helvetica', fontSize=10, leading=12, spaceAfter=0, spaceBefore=0,\n","                                    wordWrap='CJK')\n","        header_style = ParagraphStyle('HeaderStyle', parent=styles['Normal'],\n","                                      fontName='Helvetica-Bold', fontSize=12, textColor=colors.whitesmoke,\n","                                      alignment=1)\n","\n","        output_path = str(Path(output_dir) / f\"session_{class_id}_transcript_simple.pdf\")\n","        doc = SimpleDocTemplate(output_path, pagesize=letter,\n","                                rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=72)\n","\n","        elements = []\n","        title = Paragraph(f\"Session {class_id}\", styles['Title'])\n","        date_str = datetime.now().strftime(\"%Y-%m-%d\")\n","        subtitle = Paragraph(f\"Generated on {date_str}\", styles['Heading2'])\n","        elements.append(title)\n","        elements.append(subtitle)\n","        elements.append(Spacer(1, 12))\n","\n","        data = [[Paragraph('Time', header_style), Paragraph('Text', header_style)]]\n","        for seg in transcript_data['segments']:\n","            minutes = int(seg['start'] // 60)\n","            seconds = int(seg['start'] % 60)\n","            timestamp = f\"{minutes:02d}:{seconds:02d}\"\n","            data.append([\n","                timestamp,\n","                Paragraph(normalize_sentence_spacing(seg['text']), text_style)\n","            ])\n","\n","        table = Table(data, colWidths=[0.75*inch, 6.25*inch], repeatRows=1)\n","        table.setStyle(TableStyle([\n","            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n","            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n","            ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n","            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n","            ('FONTSIZE', (0, 1), (-1, -1), 10),\n","            ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n","            ('GRID', (0, 0), (-1, -1), 1, colors.black),\n","            ('LEFTPADDING', (0, 0), (-1, -1), 6),\n","            ('RIGHTPADDING', (0, 0), (-1, -1), 6),\n","            ('TOPPADDING', (0, 0), (-1, -1), 3),\n","            ('BOTTOMPADDING', (0, 0), (-1, -1), 3),\n","        ]))\n","        elements.append(table)\n","        doc.build(elements)\n","        print(f\"Created simplified PDF transcript: {output_path}\")\n","        return output_path\n","    except Exception as e:\n","        print(f\"Error creating simplified transcript: {str(e)}\")\n","        return None"]},{"cell_type":"code","source":["def _emit_outputs(class_id, headers, privacy_mode: str, output_dir: str):\n","    \"\"\"\n","    Builds PDF/CSV for names, ids, or both, into the given output_dir.\n","    Returns a dict of produced file paths.\n","    \"\"\"\n","    outputs = {}\n","    if privacy_mode == \"both\":\n","        # Names versions\n","        outputs['pdf_names'] = compile_transcript_to_pdf(class_id, headers, name_mode=\"names\", file_suffix=\"_names\", output_dir=output_dir)\n","        outputs['csv_names'] = compile_transcript_to_csv(class_id, headers, name_mode=\"names\", file_suffix=\"_names\", output_dir=output_dir)\n","        # IDs versions\n","        outputs['pdf_ids'] = compile_transcript_to_pdf(class_id, headers, name_mode=\"ids\", file_suffix=\"_ids\", output_dir=output_dir)\n","        outputs['csv_ids'] = compile_transcript_to_csv(class_id, headers, name_mode=\"ids\", file_suffix=\"_ids\", output_dir=output_dir)\n","    else:\n","        suffix = \"\" if privacy_mode == \"names\" else \"_ids\"\n","        outputs['pdf'] = compile_transcript_to_pdf(class_id, headers, name_mode=privacy_mode, file_suffix=suffix, output_dir=output_dir)\n","        outputs['csv'] = compile_transcript_to_csv(class_id, headers, name_mode=privacy_mode, file_suffix=suffix, output_dir=output_dir)\n","    return outputs\n","\n","def _print_outputs(outputs: dict, privacy_mode: str):\n","    \"\"\"Console-print produced file paths; supports single or 'both' privacy modes.\"\"\"\n","    if privacy_mode == \"both\":\n","        print(\"\\nSuccess! Your transcripts are ready (both versions):\")\n","        print(f\"PDF (names): {outputs.get('pdf_names')}\")\n","        print(f\"CSV (names): {outputs.get('csv_names')}\")\n","        print(f\"PDF (ids):   {outputs.get('pdf_ids')}\")\n","        print(f\"CSV (ids):   {outputs.get('csv_ids')}\")\n","    else:\n","        print(\"\\nSuccess! Your transcripts are ready:\")\n","        print(f\"PDF: {outputs.get('pdf')}\")\n","        print(f\"CSV: {outputs.get('csv')}\")"],"metadata":{"id":"JPIaN7HMyJGJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uoDrTYAqq2JO"},"source":["<div style=\"border:2px solid #D35400;padding:12px;border-radius:8px;background:#FFF7F0\">\n","<h3>Section: Pipeline Entrypoint</h3>\n","<p>Runs: fetch → preprocess → transcribe → compile. Prints output paths and a caution to double-check accuracy.</p>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dbtt5NLEYHvL"},"outputs":[],"source":["# @title\n","def process_lecture(audio_path, class_id, curl_string):\n","    \"\"\"\n","    End-to-end pipeline with graceful fallbacks.\n","    \"\"\"\n","    output_pdf, output_csv = None, None  # NEW: ensure defined for the return\n","    try:\n","        # 1) Forum events\n","        print(\"Step 1/4: Processing Forum class events...\")\n","        headers = clean_curl(curl_string)\n","        events_data = get_forum_events(class_id, headers)\n","\n","        # 2) Audio preprocess\n","        print(\"\\nStep 2/4: Preprocessing audio file...\")\n","        preprocessor = AudioPreprocessor()\n","        fixed_path = preprocessor.validate_and_fix_file(audio_path)\n","\n","        # 3) Transcribe\n","        print(\"\\nStep 3/4: Generating transcript...\")\n","        tp = TranscriptionProcessor()\n","        transcript_path = tp.transcribe(fixed_path, class_id)\n","\n","        # 4) Compile outputs\n","        print(\"\\nStep 4/4: Compiling final PDF and CSV transcripts...\")\n","        try:\n","            outputs = _emit_outputs(class_id, headers, PRIVACY_MODE, OUTPUT_DIR)\n","            _print_outputs(outputs, PRIVACY_MODE)\n","\n","            # NEW: choose representative return values\n","            if PRIVACY_MODE == \"both\":\n","                output_pdf = outputs.get('pdf_names') or outputs.get('pdf_ids')\n","                output_csv = outputs.get('csv_names') or outputs.get('csv_ids')\n","            else:\n","                output_pdf = outputs.get('pdf')\n","                output_csv = outputs.get('csv')\n","\n","            # NEW: accuracy caution banner\n","            print(\"\\n⚠️  Accuracy caution: Do not rely solely on this transcript. Manually verify key information.\")\n","\n","        except Exception as e:\n","            print(f\"Error compiling transcripts: {str(e)}\")\n","            print(\"Attempting to create simplified transcripts without speaker information...\")\n","            # Simplified outputs don't include names/attendance, so privacy mode is irrelevant here\n","            output_pdf = create_simplified_transcript(class_id, transcript_path, OUTPUT_DIR)\n","            output_csv = create_simplified_csv(class_id, transcript_path, OUTPUT_DIR)\n","            if output_pdf and output_csv:\n","              print(f\"\\nCreated simplified transcripts:\")\n","              print(f\"PDF: {output_pdf}\")\n","              print(f\"CSV: {output_csv}\")\n","              print(\"\\n⚠️  Accuracy caution: Do not rely solely on this transcript. Manually verify key information.\")\n","\n","            else:\n","                print(\"Failed to create simplified transcripts.\")\n","                return None, None\n","\n","        # Cleanup converted audio\n","        try:\n","            temp_files = [fixed_path]\n","            for temp_file in temp_files:\n","                if temp_file != audio_path and Path(temp_file).exists():\n","                    Path(temp_file).unlink()\n","                    print(f\"Cleaned up temporary file: {temp_file}\")\n","        except Exception as cleanup_error:\n","            print(f\"Note: Could not clean up temporary files: {str(cleanup_error)}\")\n","\n","        return output_pdf, output_csv\n","\n","    except Exception as e:\n","        print(f\"\\nERROR: {str(e)}\")\n","        if \"MP4\" in str(e) and audio_path.lower().endswith('.mp4'):\n","            print(\"\\nThere was a problem with your MP4 file. Suggestions:\")\n","            print(\"1. Convert it to MP3 on your computer before uploading\")\n","            print(\"2. Use a screen recorder to record Forum while playing back the class\")\n","            print(\"3. Contact Forum support about MP4 download issues\")\n","        else:\n","            print(\"\\nTranscription failed. Please try again with a different file.\")\n","        return None, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hTsg4BCLYKRM"},"outputs":[],"source":["# Run the process\n","pdf_output, csv_output = process_lecture(AUDIO_PATH, CLASS_ID, raw_curl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3BH0hikrkBQ"},"outputs":[],"source":["free_cuda_mem()\n","\n","print(\"CUDA cache cleared\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1-DwJxfK7hdhljFv-MwyPCfgbcJlyd3wj","timestamp":1755819388381}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}